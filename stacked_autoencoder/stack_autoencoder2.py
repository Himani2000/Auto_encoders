# -*- coding: utf-8 -*-
"""stack_autoencoder2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E8lfLmA80VyHLS62-KDWOXr2-q15ug0X
"""

#In this the stack autoencoder is implemented using tensorflow in the mnist dataset
# The concept is  to reduce the training time we tied the weights of the encoder to the decoder using the fact that
# the weight matrix  of the decoder will be the transpose of the weight matrix of the encoder

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets("MNIST_data/", one_hot = True)

mnist.validation.images.shape

n_input=784
n_hidden1=300
n_hidden2=150
n_hidden3=300
n_out=784
learning_rate = 0.01
l2_reg = 0.0005


x=tf.placeholder("float",shape=[None,n_input])
regularizer = tf.contrib.layers.l2_regularizer(l2_reg)

weights1=tf.Variable(tf.random_normal([n_input,n_hidden1]))
weights2=tf.Variable(tf.random_normal([n_hidden1,n_hidden2]))
weights3=tf.transpose(weights2)
weights4=tf.transpose(weights1)

biases1 = tf.Variable(tf.zeros(n_hidden1))
biases2 = tf.Variable(tf.zeros(n_hidden2))
biases3 = tf.Variable(tf.zeros(n_hidden3))
biases4 = tf.Variable(tf.zeros(n_out))

hidden1=tf.add(tf.matmul(x,weights1),biases1)
hidden1=tf.nn.relu(hidden1)

hidden2=tf.add(tf.matmul(hidden1,weights2),biases2)
hidden2=tf.nn.relu(hidden2)

hidden3=tf.add(tf.matmul(hidden2,weights3),biases3)
hidden3=tf.nn.relu(hidden3)

output=tf.add(tf.matmul(hidden3,weights4),biases4)
output=tf.nn.relu(output)

cost=tf.reduce_mean(tf.square(output-x))
reg_loss = regularizer(weights1) + regularizer(weights2)
loss = cost + reg_loss

optimizer = tf.train.AdamOptimizer(learning_rate)
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()

n_epochs=5
batch_size=100

with tf.Session() as sess:
  init.run()
  for i in range(n_epochs):
    n_batches = mnist.train.num_examples // batch_size
    total_cost=0
    for j in range(n_batches):
      x_batch,y_batch=mnist.train.next_batch(batch_size)
      c,_=sess.run([cost,training_op], feed_dict={x: x_batch})
      total_cost+=c
    print("MSE",c) 
  pred=sess.run(output,feed_dict={x:mnist.test.images})

first_image=mnist.test.images[1]
first_image=np.array(first_image,"float")
first_image=first_image.reshape((28,28))
plt.imshow(first_image)
plt.show()

image=pred[0]
image=np.array(image,"float")
image=image.reshape((28,28))
plt.imshow(image)
plt.show()

predictions=tf.argmax(pred,axis=1)

predictions

